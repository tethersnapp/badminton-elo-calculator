{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcExpected(player1rank,player2rank,totalScore):\n",
    "    #As ranking increase you expect to win a greater proportion of points\n",
    "    #Checks the proportion of total points to give you your expected point total.\n",
    "    #This means similar rankings expect close games thus little change\n",
    "    #Really different rankigns expect a much greater score difference. \n",
    "    #Example: 600 beats 400; 21-10\n",
    "    #If you want to make the ranks more sparse, you can reduce starting values\n",
    "    #Or increase the variation\n",
    "    #There is a function below so you can see the effect of adjusting the variation\n",
    "    variation=400\n",
    "    expected=totalScore/(1+10**((player1rank-player2rank)/variation))\n",
    "    return(expected)\n",
    "\n",
    "#REDUNDENT with new method. Use Predicted score difference instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only to verify above procedure. \n",
    "#If these scores were reached there shouldn't be any change to peoples ranks.\n",
    "def predictScore(rank1,rank2):\n",
    "    variation=670\n",
    "    expected=1/(1+10**((rank1-rank2)/variation))\n",
    "    if expected<0.475:\n",
    "        score=int((21*expected)/(1-expected))\n",
    "        return(21,score)\n",
    "    elif expected<0.5:\n",
    "        score=int(min((2*expected)/(1-2*expected),29))\n",
    "        return(min(score+2,30),score)\n",
    "    elif expected==0.5:\n",
    "        return(21,21)\n",
    "    elif expected<0.525:\n",
    "        expected=1-expected\n",
    "        score=int(min((2*expected)/(1-2*expected),29))\n",
    "        return(score,min(score+2,30))\n",
    "    elif expected<1:\n",
    "        expected=1-expected\n",
    "        score=int((21*expected)/(1-expected))\n",
    "        return(score,21)\n",
    "    else:\n",
    "        print(\"Not possible to compute\")\n",
    "        return(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcExpectedPointDiff(player1rank,player2rank):\n",
    "    x=predictScore(player1rank,player2rank)\n",
    "    return(x[0]-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRanks():\n",
    "    dic={}\n",
    "    # This is to import the data\n",
    "    dataset=pd.read_csv('testdata.csv')\n",
    "    \n",
    "    #Sensitivity adjusts how drastically the scores change per game\n",
    "    sen=7\n",
    "    \n",
    "    #Iterates over each game. Must be chronological\n",
    "    for i,(col1,score1,score2,col2) in dataset.iterrows():\n",
    "        #This formats the names so that it doesnt matter if you added a spacebar\n",
    "        name1=col1.strip().upper()\n",
    "        name2=col2.strip().upper()\n",
    "        \n",
    "        #This creates a new player in the dictionary if it hasn't been seen before.\n",
    "        if name1 not in dic:\n",
    "            dic[name1]=400\n",
    "        if name2 not in dic:\n",
    "            dic[name2]=400\n",
    "            \n",
    "        #Calculates expected score as a function of current rankings, and total score of the game\n",
    "        #escore1=calcExpected(dic[name1],dic[name2],score1+score2)\n",
    "        #escore2=calcExpected(dic[name2],dic[name1],score1+score2)\n",
    "        \n",
    "        #The change is then added and subtracted accordingly\n",
    "        #change1=int(sen*(score1-escore1))\n",
    "        #change2=int(sen*(score2-escore2))\n",
    "        #dic[name1]=1+dic[name1]+change1\n",
    "        #dic[name2]=1+dic[name2]+change2\n",
    "        \n",
    "        #Used score to represent points won minus points lost\n",
    "        pointDiff=score1-score2\n",
    "        ePointDiff=calcExpectedPointDiff(dic[name1],dic[name2])\n",
    "        change=sen*(pointDiff-ePointDiff)\n",
    "        dic[name1]=2+dic[name1]+change\n",
    "        dic[name2]=2+dic[name2]-change\n",
    "    return(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderPlayers(elo):\n",
    "    players=[str(A) for A in elo]\n",
    "    for index in range(1,len(players)):\n",
    "    #index is the one we are inserting (using insertion sort)\n",
    "        player=players[index]\n",
    "        value=elo[player]\n",
    "        i=index-1\n",
    "        while i>=0:\n",
    "            #if score is more than the person to the left, swap, keep doing till done\n",
    "            if value>elo[players[i]]:\n",
    "                players[i+1]=players[i]\n",
    "                players[i]=player\n",
    "                i=i-1\n",
    "            else:\n",
    "                break\n",
    "    scores=[elo[plyr] for plyr in players]\n",
    "    return(players,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ANUJ', 'C', 'B', 'F', 'H', 'D', 'E', 'G'],\n",
       " [581, 553, 471, 469, 438, 346, 280, 226])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eloScores=calcRanks()\n",
    "orderPlayers(eloScores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 1)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can check the prediced score using player ranks as follows.\n",
    "#Adjust this my changing variation in predict scores\n",
    "#higher variation predicts closer game => ranks will be all closer together\n",
    "#If we adjust variation such that a 200 difference in rank, gives us 21-5. Use 340. For 21-10 use 670\n",
    "predictScore(1000,237)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
